<!DOCTYPE html>
<html lang="en"><head>
<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/tabby.min.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.5.57">

  <meta name="author" content="Dr.&nbsp;Manika Lamba">
  <title>Natural Language Searching</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="index_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="index_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="index_files/libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="styles.css">
  <link href="index_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Natural Language Searching</h1>
  <p class="subtitle">LIS 4/5523: Online Information Retrieval</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Dr.&nbsp;Manika Lamba 
</div>
</div>
</div>

</section>
<section id="introduction" class="slide level2">
<h2>Introduction</h2>
<ul>
<li>Free text searching = flexiblity + complexity</li>
<li>NLP is essential for modern IR</li>
<li>Conversational interfaces are shaping the future in library search</li>
</ul>
<aside class="notes">
<p>In this lecture, we are going to discuss natural language search and its role in modern information retrieval.</p>
<p>First, we will discuss how free text searching represents both an opportunity and a challenge. Its flexibility allows users to articulate queries in their own words, fostering inclusivity and accessibility. Yet this same flexibility introduces complexity, requiring sophisticated processing to manage linguistic ambiguity, synonymy, and varying query structures. The effectiveness of free text search therefore depends on the strength of the underlying linguistic and computational models.</p>
<p>Second, we will see how Natural Language Processing has become indispensable for contemporary information retrieval. From tokenization and indexing to intent detection and semantic modeling, NLP techniques enable systems to move beyond surface-level keyword matching toward genuine understanding of user queries and document meaning. NLP thus serves as the foundation upon which intelligent, adaptive, and context-aware retrieval systems are built.</p>
<p>Finally, we will discuss how conversational interfaces—including voice-based assistants and chatbots—are reshaping the landscape of library search and discovery. By facilitating dialogue-like interactions, these systems make information retrieval more natural, accessible, and responsive. They extend the mission of libraries by offering scalable, human-centered engagement, and they signal the ongoing convergence of librarianship, computational linguistics, and artificial intelligence.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="document-indexing-and-retrieval" class="slide level2">
<h2>Document Indexing and Retrieval</h2>
<ul>
<li>Methods include
<ul>
<li>Boolean</li>
<li>Vector Space</li>
<li>Probabilistic</li>
</ul></li>
<li>Rely on <em>index terms</em>
<ul>
<li><em>“bag of words”</em></li>
<li>stoplist + stemming</li>
</ul></li>
<li>But text is “unstructured”
<ul>
<li>information may be “hidden”</li>
</ul></li>
</ul>
<aside class="notes">
<p>In earlier modules, we covered the three core <strong>document retrieval strategies</strong>: (i) <strong>Boolean</strong>, (ii) <strong>Vector Space</strong>, and (iii) <strong>Probabilistic</strong> models.</p>
<p>All of these models depend on <strong>index terms</strong>, which are the keywords or tokens that represent the main ideas in a document. This is often referred to as the <strong>“bag of words”</strong> approach where the information system treats each document as an unordered collection of words, ignoring sentence structure or grammar. To make this more efficient, we use <strong>stoplists</strong> to filter out common, low-value words (like “the,” “is,” or “and”) and <strong>stemming</strong> to reduce words to their root forms, such as turning “learning,” “learns,” and “learned” into “learn.”</p>
<p>However, the limitation here is that <strong>text is unstructured</strong>. It doesn’t follow a fixed schema like a database, that is, meaning, context, and relationships between words are often <strong>hidden</strong>. A keyword match might miss the nuance of how terms are actually used.</p>
<p>This challenge led to the evolution toward <strong>free-text</strong> and <strong>natural language searching</strong>. Instead of relying only on index terms or Boolean logic, these approaches allow users to search using <strong>everyday language</strong>, such as typing “What are the best ways to learn machine learning?” rather than just “machine learning AND tutorial.”</p>
<p>Here’s where Natural Language Processing comes in —- it builds on these traditional retrieval models by helping computers interpret meaning, context, and intent behind a query. NLP-enhanced search systems can understand synonyms, recognize entities, and analyze sentiment — turning unstructured text into structured, meaningful data that can be retrieved intelligently.</p>
<p>So, in essence, Boolean, vector, and probabilistic models gave us the foundation for <strong>structured retrieval</strong>, while NLP and semantic understanding expanded that foundation into <strong>natural, conversational searching</strong> — the kind of search experience we now expect on platforms like Google, YouTube, and social media.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="problems-with-text" class="slide level2 smaller">
<h2>Problems with Text</h2>
<ul>
<li><code>Polysemy</code>: one word maps to many concept such as bat</li>
<li><code>Synonymy</code>: one concept maps to many words such as happy or joyful, car or automobile</li>
<li><code>Word order</code></li>
<li><code>Language is generative</code>
<ul>
<li><p><em>Starbucks coffee is the best</em></p></li>
<li><p><em>The place I like most when I need to feed my caffeine addiction is the company from Seattle with branches everywhere</em></p></li>
</ul></li>
<li><code>Many different ways to express given idea</code>
<ul>
<li>synonymy, paraphrase, metaphor, etc</li>
</ul></li>
<li><code>Frege's principle</code>: <em>The meaning of a sentence is completely determined by the meaning of its symbols and the syntax used to combine them</em></li>
</ul>
<aside class="notes">
<p>When we work with text data, one of the biggest challenges is that <strong>human language isn’t straightforward</strong>. There are many ways to say the same thing, and words often mean different things depending on context — which makes text processing far more complex than working with structured data like numbers or categories.</p>
<p>Let’s look at a few of the main <strong>problems with text</strong>.</p>
<p>First, there’s <strong>polysemy</strong>, which means a single word can have <strong>multiple meanings</strong>. For example, the word <em>“bat”</em> can refer to an animal or a piece of sports equipment. Humans can easily infer which meaning is intended from context, but a computer can’t do that without additional processing or training.</p>
<p>Next, we have <strong>synonymy</strong>, which is the opposite issue -— one concept can be expressed using <strong>many different words</strong>. For example, <em>“happy”</em> and <em>“joyful”</em>, or <em>“car”</em> and <em>“automobile”</em>, all convey the same idea. For a computer that relies on exact word matching, these differences can cause it to miss relevant information.</p>
<p>Then there’s <strong>word order</strong>. In English and many other languages, the order of words changes meaning. For example, <em>“The cat chased the dog”</em> versus <em>“The dog chased the cat”</em> -— same words, completely different meaning. So, computers need to understand syntax and structure, not just individual words.</p>
<p>Another key feature of language is that it’s <strong>generative</strong> —- we can express the same thought in countless ways. For instance, consider the simple statement: <em>“Starbucks coffee is the best.”</em> You could also say, <em>“The place I like most when I need to feed my caffeine addiction is the company from Seattle with branches everywhere.”</em> Both sentences communicate the same core idea, but with very different wording, tone, and structure.</p>
<p>This flexibility through <strong>synonymy, paraphrase, metaphor, and other linguistic devices</strong> is what makes human communication rich and creative, but also what makes text so challenging for machines to process.</p>
<p>Finally, <strong>Frege’s Principle</strong> helps explain why meaning in language can be complex. It states that <em>the meaning of a sentence is completely determined by the meaning of its symbols and the syntax used to combine them.</em> In theory, this means if we understand each word and how they fit together, we should understand the sentence. In practice, though, human language often violates this principle through context, idioms, and implied meaning which is exactly why Natural Language Processing is so essential for text understanding and information retrieval.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="problems-with-text-cont." class="slide level2 smaller">
<h2>Problems with Text (Cont.)</h2>
<ul>
<li><code>Language is a form of communication</code>
<ul>
<li>All communication has a *context*
<ul>
<li><strong><em>time</em></strong> and <strong><em>place</em></strong> of utterance, the writer, the reader, their <strong>background knowledge</strong>, <strong>intentions</strong>, <strong>assumptions</strong> and the reader’s knowledge/intentions, etc.</li>
</ul></li>
</ul></li>
<li><code>Language is changing</code></li>
<li><code>Ill-formed input</code></li>
<li><code>Co-ordination, negation, etc</code></li>
<li><code>Multi-linguity</code></li>
<li><code>Sarcasm, irony, slang, jargon, etc</code></li>
</ul>
<aside class="notes">
<p>Continuing our discussion on the <strong>problems with text</strong>, we now move beyond just word meaning and structure to look at some deeper challenges that come from the nature of <strong>language as communication</strong>.</p>
<p>First and foremost, <strong>language is a form of communication</strong>, and all communication happens within a <strong>context</strong>. This means that understanding language requires knowing the <strong>time and place</strong> of the utterance, who the <strong>writer or speaker</strong> is, who the <strong>reader or listener</strong> is, and what <strong>background knowledge</strong>, <strong>intentions</strong>, and <strong>assumptions</strong> each person brings. For example, a tweet made during a political event or a comment on a breaking news story may carry meaning that’s only clear when you know when and where it was posted. Without context, computers can easily misinterpret meaning.</p>
<p>Second, <strong>language is constantly changing</strong>. New words, slang, and expressions emerge all the time, especially online. Think about how quickly terms like “ghosting,” “FOMO,” or “AI” entered common use. NLP systems must continually adapt to stay current with these shifts in language and culture.</p>
<p>Next, we have <strong>ill-formed input</strong>, which refers to the fact that people often type or speak in ways that are incomplete, ungrammatical, or filled with typos, abbreviations, and emojis. On social media especially, posts rarely follow perfect grammar rules, so NLP models need to handle noisy, messy data.</p>
<p>Another issue is <strong>coordination and negation</strong>, things like <em>“Mary got home late, and she missed her dinner”</em> or <em>“I don’t dislike this movie.”</em> These constructions can be tricky because meaning changes depending on how clauses are linked or negated. Understanding such nuances requires more than simple word-level analysis.</p>
<p>Then there’s <strong>multilinguality</strong>, or the use of multiple languages. Many users mix languages, for example, switching between English and Spanish in the same sentence. This poses a major challenge for NLP systems that rely on monolingual training data.</p>
<p>Finally, <strong>sarcasm, irony, slang, and jargon</strong> are particularly difficult for computers to interpret. When someone says, <em>“Oh great, another meeting,”</em> they might mean the opposite of what the words literally say. Humans detect tone and social cues naturally, but for machines, this kind of subtlety often leads to misunderstanding.</p>
<p>So, these challenges highlight why <strong>language understanding is far more than pattern matching</strong> – it requires grasping context, culture, tone, and evolution. And that’s exactly why NLP research continues to evolve -— to make computers better at interpreting human communication in all its complexity.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="enter-nlptext-analytics" class="slide level2">
<h2>Enter NLP/Text Analytics</h2>
<ul>
<li><p><code>Text Analytics</code>: a set of <strong>linguistic, analytical</strong>, and <strong>predictive</strong> technique to extract <strong>structure</strong> and <strong>meaning</strong> from unstructured documents</p></li>
<li><p><code>NLP</code>: academic term for Text Analytics</p>
<ul>
<li>analogous to “search” vs.&nbsp;“IR”</li>
<li>Text Analytics ≈ NLP ≈ Text Mining</li>
</ul></li>
</ul>

<img data-src="images/2.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>As you can see from the previous slides, language is incredibly complex. Words can have multiple meanings. All of these make text data messy and hard for machines to interpret. So, how do we deal with this complexity? That’s where Text Analytics or Natural Language Processing (NLP) come in. These techniques give us tools to extract structure and meaning from unstructured text, helping us turn language into something computers can analyze and learn from.</p>
<p>When we talk about Text Analytics, we’re referring to a set of techniques – linguistic, analytical, and predictive — that allow us to extract structure and meaning from unstructured text data. You’ll often hear the term Natural Language Processing, or NLP, in academic contexts. Essentially, NLP is the scholarly term for what industry often calls Text Analytics. It’s similar to the distinction between “search” in everyday language and “information retrieval” in research.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="role-of-natural-language-processing-in-information-retrieval" class="title-slide slide level1 center">
<h1>Role of Natural Language Processing in Information Retrieval</h1>

</section>

<section>
<section id="natural-language-searching" class="title-slide slide level1 center">
<h1>Natural Language Searching</h1>
<aside class="notes">
<p>In recent years, there has been an unprecedented growth in unstructured text data across digital environments. Scholarly publications, institutional reports, social media content, and various forms of grey literature now constitute an immense corpus of textual information that is not easily represented within structured databases. This proliferation of unstructured text has created a pressing need for search systems that can effectively interpret and retrieve relevant information from natural language sources.</p>
<p>Historically, information retrieval systems have relied on Boolean search models, which require users to construct queries using logical operators such as AND, OR, and NOT. While Boolean searching offers precision and control, it also imposes a steep learning curve and often results in inefficiencies for non-expert users. In contrast, contemporary search interfaces increasingly emphasize natural language querying, allowing users to articulate information needs in the same way they would express them conversationally — for example, by typing or speaking full questions rather than isolated keywords.</p>
<p>This preference for natural queries reflects a broader transformation in user expectations, influenced by advances in natural language processing (NLP) and the ubiquity of intelligent search assistants. Users now anticipate that systems will interpret intent, context, and semantics, rather than rely solely on keyword matching.</p>
<p>Within libraries and digital repositories, these developments have significant implications. As curators of extensive collections of unstructured text — including research papers, theses, and archival documents — such institutions are increasingly integrating natural language search capabilities to enhance information accessibility and discovery. These systems not only support more intuitive interaction but also align with broader efforts to democratize access to scholarly knowledge.</p>
<p>The shift toward natural language searching represents a critical evolution in information retrieval, one that bridges the gap between human linguistic expression and computational understanding.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="natural-langauge-indexing" class="slide level2">
<h2>Natural Langauge Indexing</h2>
<ul>
<li><p>Based on existing vocabulary of documents</p></li>
<li><p>Terms are extracted or derived from titles, abstracts, full text</p></li>
<li><p>Terms are in title, abstract, descriptor, full-text fields</p></li>
<li><p>Searcher inputs any term likely to occur in free text</p></li>
</ul>
<aside class="notes">
<p>Natural Language Indexing is the form of indexing language which is used to represent subjects of object in a database. It does not use a controlled vocabulary as the source for indexing terms. Instead it is based on the existing vocabulary of the object being represented. Terms are extracted from the body of the object text or derived from titles or abstracts of the object.</p>
<p>Any term or concept that is present in the object may be deemed important and therefore can be represented in the record describing the object.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="nlp-applications-in-searching" class="slide level2 smaller">
<h2>NLP Applications in Searching</h2>
<ol type="1">
<li>Word Prediction
<ul>
<li>Assistive technologies (TextHelp)</li>
<li>Google, Bing, Yahoo query suggestions</li>
</ul></li>
</ol>

<img data-src="images/7.png" class="quarto-figure quarto-figure-center r-stretch" width="402"><aside class="notes">
<p>NLP plays a central role in enhancing how users interact with search systems, particularly by improving query formulation, interpretation, and completion. One prominent area of application is word prediction, which assists users in constructing queries more efficiently and accurately. By analyzing large corpora of search behavior and linguistic patterns, NLP models can anticipate what a user is likely to type next, reducing effort and improving precision in information retrieval.</p>
<p>This functionality is integral to assistive technologies, such as TextHelp and similar tools, which support individuals with language, literacy, or motor challenges. Through predictive text and contextual suggestions, these systems enable smoother communication and more accessible search experiences. In the context of libraries and digital repositories, such tools can be particularly valuable for users with diverse accessibility needs, helping to ensure equitable participation in digital information environments.</p>
<p>In mainstream search engines such as Google, Bing, and Yahoo, NLP powers query suggestion and auto-completion features that guide users toward refined or alternative queries. For example, as a user begins typing “library digital,” the system may suggest completions such as “library digital archives” or “library digital collections,” reflecting both linguistic context and aggregated search trends. These predictive systems rely on sophisticated language models that analyze syntax, semantics, and user intent at scale.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="nlp-applications-in-searching-1" class="slide level2 smaller">
<h2>NLP Applications in Searching</h2>
<ol start="2" type="1">
<li>Spelling Correction
<ul>
<li><p>Autocorrect <img data-src="images/3.png"></p></li>
<li><p>Did you Mean <img data-src="images/4.png"></p></li>
</ul></li>
</ol>
<aside class="notes">
<p>Another key application of NLP in search systems is <strong>spelling correction</strong>, which directly improves the accuracy and usability of information retrieval. Users frequently make typographical errors, omit letters, or misremember proper names, and without automated correction, such errors would significantly degrade retrieval performance.</p>
<p>The first and most familiar implementation of this is <strong>autocorrect</strong>. Autocorrect mechanisms use NLP models trained on extensive language corpora and user query logs to identify likely misspellings and replace them with the intended terms in real time. For instance, when a user types “envrionmental policy,” the system automatically recognizes the anomaly and corrects it to “environmental policy.” These systems typically rely on probabilistic models, such as edit distance algorithms, phonetic similarity measures, and contextual embeddings, to determine the most plausible correction.</p>
<p>A related and widely recognized feature is the <strong>“Did you mean”</strong> suggestion, popularized by search engines such as Google and Bing. Instead of automatically replacing the query, the system proposes an alternative based on linguistic probability and query frequency. This approach maintains user agency by offering correction as a suggestion rather than enforcing substitution.</p>
<p>Both autocorrect and “Did you mean” functionalities exemplify how NLP enhances the robustness and inclusivity of search systems. They mitigate the effects of human error, non-native language use, and spelling variation, thereby improving retrieval quality and user satisfaction.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="nlp-applications-in-searching-2" class="slide level2 smaller">
<h2>NLP Applications in Searching</h2>
<ol start="3" type="1">
<li><p>Text Categorization</p>
<ul>
<li>News agencies: classifying incoming news stories</li>
<li>Search engines: classifying queries</li>
<li>Identifying spam emails</li>
<li>Routing email or documents to appropriate people</li>
</ul></li>
<li><p>Terminology Extraction</p>
<ul>
<li>Differentiate between useful index terms and ‘noise’</li>
<li>Help lexicographers identify new terminology</li>
<li>Term extraction systems process scientific papers to identify terminology, possibly comparing it with a known list</li>
</ul></li>
<li><p>Speech Recognition</p>
<ul>
<li>Spoken Dialogue System</li>
<li>iPhone Voice Search</li>
</ul></li>
</ol>
<aside class="notes">
<p>Beyond word prediction and spelling correction, NLP supports several additional applications that are foundational to modern information retrieval and search system design. These include <strong>text categorization, terminology extraction, and speech recognition</strong> – each addressing a distinct aspect of how systems interpret, organize, and interact with human language.</p>
<p>Text categorization refers to the automatic classification of documents or queries into predefined categories based on their content. In news agencies, for example, NLP-driven classifiers are used to automatically sort incoming stories into topical domains such as politics, economics, or sports, enabling faster editorial workflows and real-time content organization. Similarly, search engines employ query classification to interpret the intent behind a user’s input—distinguishing, for instance, whether a query is informational (“What is climate change?”), navigational (“UN Climate Report 2024”), or transactional (“buy solar panels”). Accurate classification supports more relevant ranking and personalized retrieval. In communication systems, text categorization is applied to spam detection, filtering unwanted or malicious emails by recognizing linguistic and structural patterns associated with spam content. It is also used for document routing, where NLP systems automatically direct incoming emails or reports to the appropriate department or individual, streamlining information flow within organizations.</p>
<p>Another important application is terminology extraction, which focuses on identifying and isolating domain-specific terms within large text corpora. In information retrieval, this process helps differentiate between useful index terms—those that carry semantic weight—and background “noise” such as common or generic words. For lexicographers and subject specialists, terminology extraction supports the identification of emerging concepts and new vocabulary. For instance, in scientific publishing, NLP-driven term extraction systems can analyze research articles to identify newly introduced technical terms and compare them against established term lists or ontologies. This capability is particularly valuable in building and updating controlled vocabularies, thesauri, and ontologies that underpin advanced search systems, ensuring that indexing and retrieval remain aligned with evolving disciplinary language.</p>
<p>Finally, speech recognition represents a critical bridge between spoken language and searchable text. Modern spoken dialogue systems and voice-activated assistants rely on NLP to transcribe and interpret speech, enabling users to conduct searches or issue commands using natural spoken queries. A familiar example is iPhone Voice Search (Siri), which allows users to speak queries such as “Find articles on information retrieval models” or “Where is the nearest library?” The system processes the audio input, converts it into text, applies NLP-based intent detection, and retrieves relevant results. Speech recognition not only enhances user convenience but also expands accessibility—benefiting individuals with mobility impairments, visual disabilities, or those operating in hands-free environments.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="nlp-applications-in-searching-3" class="slide level2 smaller">
<h2>NLP Applications in Searching</h2>
<ol start="6" type="1">
<li><p>Named Entity Recognition</p>
<ul>
<li>Identification of key concepts (eg. people, places, organizations)</li>
<li>Increase precision of IR (New companies in New York vs. Companies in New York)</li>
<li>Support navigation</li>
<li>Improve machine translation</li>
<li>Speech synthesis, auto-summarization, etc.</li>
</ul></li>
</ol>

<img data-src="images/10.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Named Entity Recognition, or NER, is one of the most important applications of NLP in searching. It identifies key concepts in text—things like people, places, organizations, dates, and more. It helps improve the precision of information retrieval.For example, consider the query ‘New companies in New York’. Without NER, the system might return results about any companies in New York, old or new. With NER, the system understands that ‘New’ refers to the adjective describing companies, not part of the location, and retrieves more accurate results.</p>
<p>NER also supports navigation by allowing systems to organize and filter results based on entities. Beyond search, it plays a role in machine translation, speech synthesis, and even auto-summarization because understanding entities is key to understanding meaning. NER helps search systems move beyond simple keyword matching to understanding the actual concepts users care about.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="nlp-applications-in-searching-4" class="slide level2 smaller">
<h2>NLP Applications in Searching</h2>
<ol start="7" type="1">
<li>Information Extraction
<ul>
<li>Identification of entities + relationships</li>
<li>Based on pre-defined structures</li>
<li>Can be used for metadata retrieval or store in database and query against it</li>
</ul></li>
</ol>

<img data-src="images/13.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Information Extraction goes a step beyond Named Entity Recognition. While NER identifies entities like people, places, and organizations, Information extraction looks at the relationships between those entities. For example, not just recognizing ‘John Smith’ and ‘Harvard University,’ but also understanding that John Smith is affiliated with Harvard.</p>
<p>Information Extraction typically works based on pre-defined structures or templates. These structures help the system know what kinds of relationships to look for, such as ‘author of,’ ‘located in,’ or ‘works at.’ This structured approach makes Information Extraction very useful for organizing data.</p>
<p>In the context of search, Information Extraction can be used to generate metadata automatically. For instance, extracting author names, publication dates, and affiliations from research papers and storing them in a database. Once this metadata is structured, we can query against it efficiently, improving both precision and recall.</p>
<p>Beyond search, Information Extraction supports advanced applications like building knowledge graphs, improving recommendation systems, and enabling semantic navigation in digital libraries.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="free-text-searching" class="slide level2">
<h2>Free Text Searching</h2>

<img data-src="images/15.png" class="quarto-figure quarto-figure-center r-stretch" width="565"><div class="footer">
<p>Source: Markey Ch-7</p>
</div>
<aside class="notes">
<p>Free text searching refers to a retrieval approach in which users enter search terms directly, without relying on a predefined indexing structure or controlled vocabulary. In this model, the search engine scans the text of documents—such as titles, abstracts, and full content—for matches to the words or phrases supplied by the user. This method leverages the actual language used within the corpus, allowing for flexible and dynamic searching.</p>
<p>In contrast, a controlled vocabulary system, such as the Library of Congress Subject Headings or MeSH (Medical Subject Headings), employs a standardized set of terms that describe concepts consistently across documents. Controlled vocabularies promote precision and interoperability by ensuring that related materials are indexed under the same authorized terms. However, they also require users to understand the specific terminology of the indexing schema, which can be restrictive or unintuitive for those unfamiliar with it.</p>
<p>Free text searching, by comparison, enables users to express their queries in their own words. For example, a user interested in research on renewable energy might use a keyword query such as “solar energy policy”. A natural language query, on the other hand, might take the form of “How are governments supporting the adoption of solar energy?”</p>
<p>While both approaches rely on textual input, natural language queries introduce linguistic variation, context, and intent, which can be better interpreted through natural language processing techniques. Controlled vocabularies offer precision and consistency, whereas free text searching offers accessibility and expressiveness.</p>
<p>Understanding this distinction provides the foundation for exploring how modern search systems combine these methods to achieve both semantic depth and user-centered flexibility in information retrieval.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="free-text-searching-in-databases" class="slide level2">
<h2>Free Text Searching in Databases</h2>
<ul>
<li>Terms added at the discretion of the cataloger</li>
<li>Do not come from a controlled vocabulary or from the words of the document</li>
<li>Cataloger tries to match user’s terms (user warrant)</li>
<li>Not a frequent practice</li>
<li>Can be used in combination with controlled vocabulary or natural language indexing</li>
</ul>
<aside class="notes">
<p>If a cataloger is providing free text terms, the terms are not coming from either a controlled vocabulary or from the object’s text. The cataloger decides to add terms that they believe match the user’s own search terms or that are closer to the everyday use of the term.</p>
<p>This is not a frequent practice in cataloging but if a term is very new to a language, it may not be represented in a controlled vocabulary yet, or the controlled vocabulary may use an alternate term than the one used by users or within the literature of the discipline. The cataloger would then decide to use a more commonly used term instead of one from the controlled vocabulary or the object.</p>
<p>Free text can also be used in combination with controlled vocabulary and/or natural language indexing.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="user-defined-tagging" class="slide level2 smaller">
<h2>User-Defined Tagging</h2>
<ul>
<li>Has many labels such as <code>user-supplied, folksonomy, tagging, social classification</code></li>
<li>It is really not a new practice but one that has recently become the buzz on the Web with the emergence of blogs and media sharing sites like Blogger, Flickr, YouTube, etc.
<ul>
<li>researchers in image retrieval have explored this idea</li>
<li>researchers in organization of information, thesauri development, indexing, subject representation have also explored this idea</li>
</ul></li>
<li>To date is being used to tag images, web pages, blogs, library catalogs, etc.</li>
</ul>
<aside class="notes">
<p>Currently we have seen a large amount of professional and research literature discussing an emerging form of indexing language, User-defined or User-Supplied terms. While I say it is emerging, this concept is really not a new idea to LIS. Many LIS researchers have been conducting research into this area since the 1990s. It has recently more popular on the Web with the emergence of blogs and media sharing sites like Blogger, Flickr, YouTube, etc.</p>
<p>This concept has many labels (user-supplied, folksonomy, tagging, social classification). It has yet to be decided which term will prevail, or whether or not LIS and cataloging will use these terms as a source for additional subject cataloging or not.</p>
<p>Researchers in image retrieval have explored this idea since the 1990s, and even earlier in specific image-related contexts, such as journalism or newspaper archives. Researchers in organization of information, thesauri development, indexing, subject representation have also explored this idea as a source of more user-centered subject terms or to learn more about how users naturally organize and describe subjects of objects.</p>
<p>To date it is being used to “tag” images, web pages, blogs, library catalogs, etc.</p>
<p>More research needs to be conducted into whether or not we can use these terms as a source for subject representation, or even as a means to develop more user-centered controlled vocabularies.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="coversational-search" class="slide level2">
<h2>Coversational Search</h2>
<ul>
<li>Voice-based queries</li>
<li>Chatbots in Libraries</li>
</ul>

<img data-src="images/14.png" class="quarto-figure quarto-figure-center r-stretch" width="401"><aside class="notes">
<p>Conversational search represents an important evolution in information retrieval, moving beyond traditional keyword or Boolean querying toward interactive, dialogue-based engagement bfetween users and search systems. This mode of search is often characterized by the use of voice-based queries, where users articulate information needs verbally rather than through typed input.</p>
<p>Prominent examples include Google Assistant and Amazon Alexa, which employ advanced natural language understanding to interpret queries such as “What are the latest articles on renewable energy policy?” or “Find me books on digital archiving.” Increasingly, similar conversational interfaces are being explored within library and digital repository systems, enabling users to locate materials, check availability, or receive research guidance through spoken or text-based interaction.</p>
<p>The benefits of conversational search are especially significant in terms of accessibility and inclusivity. Voice and natural language interfaces lower barriers for users who may have limited technical expertise, motor impairments, or visual disabilities. They also align with evolving expectations shaped by ubiquitous consumer technologies—where interacting with systems through natural language feels intuitive and human-like.</p>
<p>From an information science perspective, conversational search highlights the convergence of speech recognition, natural language processing, and contextual understanding, marking a shift from static query-response models to dynamic, user-centered dialogue systems.</p>
<p>Building upon the concept of conversational search, chatbots have emerged as practical implementations of natural language processing within the library context. These systems function as virtual reference services, designed to assist users in navigating library resources, answering common questions, and providing real-time guidance without direct human intervention.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="applications-in-lis" class="slide level2">
<h2>Applications in LIS</h2>
<ul>
<li>Digital libraries and institutional repositories</li>
<li>Discovery systems and OPACs</li>
<li>Personalized recommendations</li>
</ul>
<aside class="notes">
<p>The principles of natural language search have numerous and growing applications within Library and Information Science field, fundamentally transforming how users interact with information systems.</p>
<p>First, within digital libraries and institutional repositories, natural language search enables more intuitive exploration of scholarly content. Instead of requiring users to navigate complex metadata schemas or controlled vocabularies, systems can now interpret queries expressed in everyday language—facilitating discovery across articles, theses, datasets, and multimedia resources. For librarians, this enhances accessibility and aligns with open access and knowledge dissemination goals.</p>
<p>Second, discovery systems and OPACs increasingly incorporate natural language interfaces. Modern discovery layers, such as Primo, Summon, and EBSCO Discovery Service, are integrating NLP-driven ranking and query expansion capabilities. These allow users to formulate broad or conversational queries and still retrieve relevant materials without exact keyword matching. This evolution transforms the OPAC from a static catalog into a dynamic, user-centered search environment.</p>
<p>Finally, natural language understanding also supports personalized recommendation systems within LIS platforms. By analyzing user queries, search behavior, and reading patterns, these systems can suggest related materials or anticipate research needs. Such personalization extends beyond convenience, it supports scholarly serendipity, enhances learning outcomes, and fosters engagement with institutional collections.</p>
<p>Therefore, the application of natural language search in LIS reflects a shift from system-driven retrieval toward user-centered discovery, integrating linguistic intelligence into the core functions of information organization and access.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="future-directions" class="slide level2">
<h2>Future Directions</h2>
<ul>
<li>Multimodal Searching</li>
<li>Intelligent Research Assistants</li>
<li>Knowledge Graphs Integration</li>
<li>Multilingual and Cross-Lingual Search</li>
<li>More!!</li>
</ul>
<aside class="notes">
<p>Looking ahead, there are several emerging directions shaping the future of natural language search in scholarly and library contexts.</p>
<p>One key area is multimodal search, which integrates text, image, and voice inputs within a unified retrieval framework. This approach enables users to express information needs through multiple channels—for example, submitting an image of a manuscript page, describing it verbally, or typing a related phrase. Such multimodal systems hold promise for archives, museums, and digital humanities projects where non-textual artifacts are central.</p>
<p>A second direction involves the development of intelligent research assistants for scholarly environments. Building upon chatbot and dialogue technologies, these systems aim to support complex, iterative research interactions. Rather than retrieving a single result set, conversational AIs could guide users through literature review processes, suggest relevant methodologies, or identify citation networks – all within a sustained, context-aware dialogue. This represents a paradigm shift from search as a one-time transaction to search as an ongoing, collaborative process.</p>
<p>Finally, the integration of knowledge graphs offers a powerful means of connecting disparate data sources and enhancing semantic understanding. By representing entities—such as authors, institutions, topics, and publications—and their relationships, knowledge graphs allow search systems to infer deeper connections and provide richer, more explainable results. When combined with neural retrieval models, these structures enable contextualized, reasoning-based discovery across large scholarly ecosystems.</p>
<p>Collectively, these directions signal a future in which search systems evolve from passive retrieval tools into intelligent research partners, capable of understanding, reasoning, and assisting within complex academic and informational contexts.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="quarto-auto-generated-content">
<p><img src="images/ou.png" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="index_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="index_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="index_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="index_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="index_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="index_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="index_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="index_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="index_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="index_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="index_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true,"theme":"whiteboard"},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: "separate-page",

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: true,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        // For code content inside modals, clipBoardJS needs to be initialized with a container option
        // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>